{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgeEcNacHbt6g7rR8P9wfh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wohecha/HuggingFace-Unit1/blob/main/notebooks/unit7/unit7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# A2A Agent vs. Agent.\n",
        "---\n",
        "based on:\n",
        "https://huggingface.co/learn/deep-rl-course/unit7/hands-on\n",
        "\n",
        "/!\\ **This will take 5 to 8 hours of training** /!\\"
      ],
      "metadata": {
        "id": "_DFpC67ZzNgO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rules"
      ],
      "metadata": {
        "id": "zSERA9bC5aq8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) don't change observation space or action space of the agent.  \n",
        "*Model will not work during evaluation*\n",
        "2) Use Unity MLAgents trainer.\n",
        "3) to avoid bugs use the provided executable.  \n",
        "*Unity Editor can be used at your own bugs.*"
      ],
      "metadata": {
        "id": "pWMxsB5Z5dpv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "if issues: open issue on Github Repo  \n",
        "https://github.com/huggingface/deep-rl-class/issues"
      ],
      "metadata": {
        "id": "1lwBRFP-6J67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install MLAgents and executables"
      ],
      "metadata": {
        "id": "4Brl359M6TDe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conda is advised as package manager & as environment creator.  \n",
        "Install conda and create the environment."
      ],
      "metadata": {
        "id": "-6tjA8od6cU5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install conda and activate environment"
      ],
      "metadata": {
        "id": "jrgCLbRn75qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# change notebooks directory (return to root)\n",
        "%cd /content/"
      ],
      "metadata": {
        "id": "4EzchYNp8aki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and install Miniconda\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local"
      ],
      "metadata": {
        "id": "1_IjSyQm6zcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accept terms of service\n",
        "!conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main\n",
        "!conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r"
      ],
      "metadata": {
        "id": "D9hBAyYE7FiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Activate Miniconda and install Python ver 3.10.12\n",
        "!source /usr/local/bin/activate\n",
        "!conda install -q -y --prefix /usr/local python=3.10.12 ujson  # Specify the version here\n",
        "\n",
        "# Set environment variables for Python and conda paths\n",
        "!export PYTHONPATH=/usr/local/lib/python3.10/site-packages/\n",
        "!export CONDA_PREFIX=/usr/local/envs/myenv"
      ],
      "metadata": {
        "id": "a07SFX1w7JiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Python Version in New Virtual Environment (Compatible with ML-Agents)\n",
        "!python --version\n",
        "#should be 3.10.xx"
      ],
      "metadata": {
        "id": "NdRLnd3J7RNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!conda create --name rl python=3.10.12\n",
        "!conda activate rl"
      ],
      "metadata": {
        "id": "rvxKvOSy6mXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verify that environment is activated\n",
        "!echo $CONDA_DEFAULT_ENV"
      ],
      "metadata": {
        "id": "h3TL2JGb7mjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### install MLAgents"
      ],
      "metadata": {
        "id": "OHForiHT7JH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# change notebooks directory (return to /content)\n",
        "%cd /content/"
      ],
      "metadata": {
        "id": "rPtfax828VRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# clone the repository (2.63GB)\n",
        "!git clone https://github.com/Unity-Technologies/ml-agents"
      ],
      "metadata": {
        "id": "EdjCbQj28J2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%cd ml-agents\n",
        "!pip install -e ./ml-agents-envs\n",
        "!pip install -e ./ml-agents"
      ],
      "metadata": {
        "id": "jXZabHl18kBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "if having issues  \n",
        "https://github.com/Unity-Technologies/ml-agents/issues/6019"
      ],
      "metadata": {
        "id": "rrW_BoII9Mw6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### git-LFS\n",
        "Git-lfs is for versionning Large Files & should be pre installed by default since 2022  \n",
        "https://github.com/git-lfs/git-lfs/issues/3605"
      ],
      "metadata": {
        "id": "INaILgLm9cSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git-lfs"
      ],
      "metadata": {
        "id": "0iV9PUi79WJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install executables"
      ],
      "metadata": {
        "id": "j4oT9cyICwqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create directory for the executables\n",
        "!mkdir -p /content/ml-agents/training-envs-executables/linux"
      ],
      "metadata": {
        "id": "PTqy0wy3-ImU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download the executable\n",
        "!wget \"https://drive.usercontent.google.com/open?id=1sqFxbEdTMubjVktnV4C6ICjp89wLhUcP&authuser=0\" -O /content/ml-agents/training-envs-executables/linux/SoccerTwo.zip"
      ],
      "metadata": {
        "id": "fYRpXcsSC8Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unzip the executable\n",
        "!unzip -d ./training-envs-executables/linux/ ./training-envs-executables/linux/SoccerTwo.zip"
      ],
      "metadata": {
        "id": "qH3VSMPvDiAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure fil is accessible\n",
        "!chmod -R 755 ./training-envs-executables/linux/SoccerTwo\n",
        "ls -lah ./training-envs-executables/linux/"
      ],
      "metadata": {
        "id": "TdysM1TiEEsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understand MLAgents"
      ],
      "metadata": {
        "id": "_-uV_MiuEfJM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLAgents has been created by the UnityMLAgent team.  \n",
        "Documentation can be found here:  \n",
        "https://github.com/Unity-Technologies/ml-agents/blob/develop/docs/Learning-Environment-Examples.md#soccer-twos\n",
        "\n",
        "The objective of the game is to get the ball into the opponents goal while preventing the ball from entering your own goal."
      ],
      "metadata": {
        "id": "Kit61mDhEiQs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### - Reward function:\n",
        "- `1-accumulated time penalty`:  \n",
        "When ball enter opponents goal: accumulated time penalty is incremented by (1/maxStep) every fixed update & is reset to 0 at the beginning of an episode.\n",
        "- `-1`:  \n",
        "  When ball enters own goal.\n",
        "\n",
        "#### - Observation space:\n",
        "Observation space is composed of vectors of size 336:\n",
        "- 11 ray-cast foward distributed over 120° *(264 state dimmension)*\n",
        "- 3 ray-cast backward distributed over 90° *(72 states dimensions)*\n",
        "- Both of these ray cast can detect 6 objects:\n",
        "  - Ball\n",
        "  - Blue Goal\n",
        "  - Purple Goal\n",
        "  - Wall\n",
        "  - Blue Agent\n",
        "  - Purple Agent\n",
        "\n",
        "#### - Action Space:\n",
        "the action space is 3 discrete branches:\n",
        "- Forward: up/dn\n",
        "- Sideways: left/right\n",
        "- Rotation: left/right"
      ],
      "metadata": {
        "id": "Kj47U23-E0At"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Undertanding MA-POCA"
      ],
      "metadata": {
        "id": "cp3CRMaIHUnS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MA-POCA: *Multi-Agent POsthumous Credit Assignment*:\n",
        "##### Context:\n",
        "Self-play is great for 1 vs. 1.  \n",
        "In our case: we are 2 vs. 2 ( each team has 2 agents) and cooperative behaviour is required.\n",
        "\n",
        "Agents receive a reward as a group (+1 - penalty) when team scores a goal.  \n",
        "-> Every agent on the team is rewarded even if each agent didn't contribute the same to the win;  \n",
        "\n",
        "<i>Source: Unity Blog:<a href=\"https://blog.unity.com/technology/ml-agents-v20-release-now-supports-training-complex-cooperative-behaviors\" target=\"_blank\" rel=\"noopener noreferrer\"> ML-Agents v2.0</a></i>\n",
        "\n",
        "##### Problem:\n",
        "But this makes it difficult for an agent to learn what to do independently.\n",
        "\n",
        "##### Solution:\n",
        "Unity MLAgents team has developed a solution in a multi-agent trainer fashion called **MA-POCA: *Multi-Agent POsthumous Credit Assignment***.\n",
        "\n",
        "##### The idea:\n",
        "A centralized critic processes the state of all agents in the team to estimate the performance of each agent.\n",
        "\n",
        "this enables the agent to:  \n",
        "- make decisions based only on what it perceives locally.\n",
        "- Simultaneously evaluate how its actions performs in the context of the whole group.\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit10/mapoca.png\"  height='400' style=\"height:400px;\" alt=\"MlAgents learn\"/>\n",
        "<figcaption>source: <a href=\"https://blog.unity.com/technology/ml-agents-plays-dodgeball\" target=\"_blank\" rel=\"noopener noreferrer\">MLAgents Plays Dogeball</a>\n",
        "<figcaption>\n",
        "</figure>\n",
        "\n",
        "#### Self-play with a MA-POCA-trainer:\n",
        "\n",
        "- Poca trainer will help train cooperative behavior\n",
        "- Self-play will help to win against opponent team.\n",
        "\n",
        "\n",
        "More information: https://arxiv.org/pdf/2111.05992.pdf"
      ],
      "metadata": {
        "id": "8y09qgHxHr3z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Config.yaml"
      ],
      "metadata": {
        "id": "vV1-GMgmKwSH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please see documentation for more information on the hyperparameters of the config file:  \n",
        "https://github.com/Unity-Technologies/ml-agents/blob/release_20_docs/docs/Training-Configuration-File.md\n"
      ],
      "metadata": {
        "id": "1oFIKyXSO1xv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config=\"\"\"\n",
        "behaviors:\n",
        "  SoccerTwos:\n",
        "    trainer_type: poca\n",
        "    hyperparameters:\n",
        "      batch_size: 2048\n",
        "      buffer_size: 20480\n",
        "      learning_rate: 0.0003\n",
        "      beta: 0.005\n",
        "      epsilon: 0.2\n",
        "      lambd: 0.95\n",
        "      num_epoch: 3\n",
        "      learning_rate_schedule: constant\n",
        "    network_settings:\n",
        "      normalize: false\n",
        "      hidden_units: 512\n",
        "      num_layers: 2\n",
        "      vis_encode_type: simple\n",
        "    reward_signals:\n",
        "      extrinsic:\n",
        "        gamma: 0.99\n",
        "        strength: 1.0\n",
        "    keep_checkpoints: 5\n",
        "    max_steps: 5000000 # 5M (recommended value: will take 5 to 8 hours of training)\n",
        "    time_horizon: 1000\n",
        "    summary_freq: 10000\n",
        "    self_play:\n",
        "      save_steps: 50000\n",
        "      team_change: 200000\n",
        "      swap_steps: 2000\n",
        "      window: 10\n",
        "      play_against_latest_model_ratio: 0.5\n",
        "      initial_elo: 1200.0\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "_etSPXXOPHvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write config file\n",
        "fname=\"/content/ml-agents/config/poca/SoccerTwos.yaml\n",
        "with open(fname, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(config)"
      ],
      "metadata": {
        "id": "3RBz5o5OPYRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "uGlXtq9FQD0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5M timesteps is the recommended value.  \n",
        "This might take around 5 to 8 hours of training."
      ],
      "metadata": {
        "id": "qbaXZVZ_RgZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mlagents-learn fname \\\n",
        "--env /content/ml-agents/training-envs-executables/linux/training-envs-executables/SoccerTwo \\\n",
        "--run-id \"SoccerTwos\" \\\n",
        "--no-graphics"
      ],
      "metadata": {
        "id": "xLpQK8JyQHzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dOA4134lQSlb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}